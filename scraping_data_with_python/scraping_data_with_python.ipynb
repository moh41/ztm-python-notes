{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web scraping** is programmatically extracting data from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites may have a robots.txt file that tells web crawlers what pages they're allowed and disallowed to crawl. Any routes that are not disallowed are generally allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What To Do Next With Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use BeautifulSoup with Requests, but you can also look into APIs that are provided for websites instead. You can also use a framework (similar to a new language) called Scrapy that helps you extract data. As we extract more data, we might want to use databases to store the data. Things like MongoDB, Redis, MySQL, PostgreSQL, and more are all great options.\n",
    "\n",
    "Overall please be nice and ethical when scraping."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a23238b22d0e83c1704f993aada4b11b330ee1fc6ea5fc3a1c4c03d39a35b23d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
