{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we imported the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs (data): X\n",
    "X = iris.data\n",
    "# Outputs (target): y\n",
    "y = iris.target\n",
    "# Each column in X is a \"feature\"\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this is supervised learning, where we have labels and we have the answers to our data. We need to make a function that gives us a desired output (model) which the machine will be able to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data into training set and test set.\n",
    "\n",
    "`train_test_split` splits arrays or matrices into random train and test subsets. We return a dimensionality of the array with `.shape`. We can see the number of rows change based on the `test_size` to easily try different train and test data sizes. Ideally we want more train data than tests to have more data for a better model.\n",
    "\n",
    "But if our `test_size` is very small (while our train size is large), we can't be certain if our model is accurate because we only test it  a few times. So there is a trade off with test and train data, so the more data we have the more we can train models. This is an area for improvement of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a model, train it, and have predictions on our test data.\n",
    "\n",
    "Since we gave our model the `X_test` data, we already have the answers to them with `y_test` data. So now we can compare our predictions from the model with the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check our model's output and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could collect more data, then more features (columns) would help provide our machines more information that may help build a better model.\n",
    "\n",
    "We could use other algorithms if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(knn, \"mlbrain.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 2, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load(\"mlbrain.joblib\")\n",
    "model.predict(X_test)\n",
    "sample = [[3, 5, 4, 2], [2, 3, 5, 4]]\n",
    "predictions = model.predict(sample)\n",
    "pred_species = [iris.target_names[p] for p in predictions]\n",
    "print(pred_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model persistence** allows us to run and **save the model** so that we don't have to train/test it like in production. We can use `joblib` to save (dump) the model and load the model for use. Whenever we want to improve a model, we can just dump it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tools for machine learning. To do good machine learning, we need big data sets.\n",
    "\n",
    "We can create **custom models** like with TensorFlow and a Machine Learning Engine.\n",
    "\n",
    "Companies provide **retrainable models** like AutoML Vision, AutoML Natural Language, AutoML Translation.\n",
    "\n",
    "Companies also provide **pre-trained models** like Vision API, Speech API, Jobs API, Natural Language API, Translation API, Video Intelligence API.\n",
    "\n",
    "The value is not necessarily in the model, but the data that we use in the model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83e6778cf11a3b06d045253d2a60c0d2c2eefb2304594b9a89168cefacc0ef79"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
